# my_zhihu_spider
爬虫　知乎用户信息
１．对用url进行缓存，防止重复请求，url来源与关注和被关注列表
2.用户信息存入mongodb
3.知乎进行了限制，所有需要调试最佳的请求间隔，监控日志，如果出现error....则用程序里面的cookie刷新页面（所以浏览器就不要清cookied）,填写验证码就可以继续爬了
